\documentclass[10pt, a4paper]{extarticle}
\usepackage{physics}
\usepackage{esint}
\usepackage{mathtools}
\usepackage{hyperref}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage[margin=0.75in]{geometry}
\usepackage{anyfontsize}
\usepackage{amsthm}
\usepackage{framed}


\theoremstyle{definition}
\newtheorem{thm}{Theorem}
\newtheorem{lem}{Lemma}[thm]
\newtheorem{cor}{Corollary}[thm]
\newtheorem{defn}{Definition}
\newtheorem{eg}{Example}
\newtheorem{ex}{Exercise}

\begin{document}
\begin{center}
	\fontsize{25}{60}\selectfont Mathematical Methods in Physics I \\
	\large Based on lectures by Dr. Ritam Mallick\\
	Notes taken by Rwik Dutta
\end{center}
\hrule
\begin{center}
	These notes are not endorsed by the lecturers, and I have modified them (often
	significantly) after lectures. They are nowhere near accurate representations of what
	was actually lectured, and in particular, all errors are almost surely mine.\footnote[1]{This is how Dexter Chua describes his lecture notes from Cambridge. I could not have described mine in any better way.}
\end{center}
\tableofcontents

\newpage

\section{Vector Analysis}
Let $\{\hat{e_i}\}$ be an orthonormal basis, i.e., $\hat{e_i}\cdot\hat{e_j}=\delta_{ij}$(where $\delta_{ij}$ represents the Kroneker delta function), of our vector space. For any vector $\vb{A}$ we have
\[\vb{A}=\sum_{i}A_i\hat{e_i}\]
where $A_i$ belong to the scalar field over which the vector space is defined, like $\mathbb{R}$ or $\mathbb{C}$.
\subsection{Products}
\begin{framed}
	\begin{defn}[Vector Product]
		We define a vector product on our basis set
		\[\hat{e_i}\times\hat{e_j}=\sum_k \epsilon_{ijk}\ \hat{e_k}\]
		The R.H.S. is a vector itself, hence, the name. Using this and the fact that vector product is distributive over addition we arrive at
		\[\vb{C}=\vb{A}\times\vb{B}=\sum_i \hat{e_i}\sum_{jk}\epsilon_{ijk}A_jB_k\]
		where \[C_i=\sum_{jk}\epsilon_{ijk}A_jB_k\]
	\end{defn}
\end{framed}
\hfill\\
Using this we can find
\begin{framed}
	\begin{thm}[Scalar triple product]
		\[\vb{A}\cdot(\vb{B}\times\vb{C})=\sum_{ijk}\epsilon_{ijk}A_iB_jC_k\]
		This is also represented as $[\vb{ABC}]$.
	\end{thm}
\end{framed}
\hfill\\
We can also calculate
\begin{framed}
	\begin{thm}[Vector triple product]
		\begin{align*}
			\vb{A}\times(\vb{B}\times\vb{C}) & =\sum_i \hat{e_i}\sum_{jk}\epsilon_{ijk}A_j\sum_{pq}\epsilon_{kpq}B_pC_q \\
			                                 & =\vb{B}(\vb{A}\cdot\vb{C})-\vb{C}(\vb{A}\cdot\vb{B})
		\end{align*}
		The vector product is not associative, hence the position of the parenthesis is important in the triple product.
	\end{thm}
\end{framed}

\begin{ex}
	Show that
	\[(\vb{A}\times\vb{B})\times(\vb{C}\times\vb{D})=[\vb{ABD}]\vb{C}-[\vb{ABC}]\vb{D}\]
\end{ex}

\subsection{Coordinate Transformation}
The rotation of the 2D coordinate axes by an angle $\phi$, keeping the origin fixed, leads to the
\begin{framed}
	\begin{defn}[Rotation transformation]
		\[\vb{A'}=S\vb{A}\]
		where $S$ is the rotation transformation represented by the matrix
		\[S=\left(\begin{matrix}
					\cos\phi  & \sin\phi \\
					-\sin\phi & \cos\phi
				\end{matrix}\right)\] in our orthonormal basis.
		It is clear that $SS^T=I$, i.e., the rotation transformation is orthogonal. It takes the same form in higher dimensions, i.e., rotation of vectors is an orthogonal transformation.
	\end{defn}
\end{framed}
This is a special property of vectors in physics. There is another kind of quantity called
\begin{framed}
	\begin{defn}[Pseudovectors]
		\[\vb{A'}=|S|S\vb{A}\]
		This is how these quantities transform under rotation, where, $S$ is again a orthogonal transformation and $|S|$ represents the determinant of $S$.
	\end{defn}
\end{framed}

\subsection{Differential Calculus}
We require the del operator
\[\grad\equiv \sum_i\hat{e_i}\pdv{}{i}\] in Cartesian coordinates. Using this we can define quantities like
\begin{framed}
	\begin{defn}[Gradient]
		\[\text{Grad }f=\grad f\]
		A small change in a scalar field along $\vb{r}$ is given by
		\[df=\vb{r}\cdot\grad f\]
		Say, the direction of $\grad f$ is given by some $\hat{r}$. We have the most rapid increase in $f$ along $\hat{r}$ and $|\grad f|=\frac{Df}{D\hat{r}}$ is the directional derivative of $f$ along $\hat{r}$.
	\end{defn}

	\begin{defn}[Divergence]
		\[\text{Div }\vb{A}=\grad\cdot\vb{A}\]
		This gives a measure of the accumulation or depletion of $\vb{A}$ at a point. In other words, it finds how strongly a point acts as a source or sink.
	\end{defn}

	\begin{defn}[Curl]
		\[\text{Curl }\vb{A}=\grad\times\vb{A}\]
		This gives a measure of the circulation of $\vb{A}$ at a point.
	\end{defn}

	\begin{defn}[Laplacian]
		\[\grad^2 f=\grad\cdot(\grad f)\]
		The Laplacian is also defined for a vector field as
		\[\grad^2\vb{A}=\sum_i \hat{e_i}\grad^2A_i\]
	\end{defn}
\end{framed}
These can also be calculated in curvilinear coordinate systems as given in \href{https://en.wikipedia.org/wiki/Del_in_cylindrical_and_spherical_coordinates}{this Wikipedia article}. 

Some useful properties of vector derivatives are
\begin{framed}
	\begin{thm}
		\begin{align*}
			\grad\times(\grad f)&=0\\
			\grad\cdot(\grad\times\vb{A})&=0\\
		\grad\times(\grad\times\vb{A})&=\grad(\grad\cdot\vb{A})-\grad^2\vb{A}
		\end{align*}
		The last one is only valid in Cartesian coordinates.
	\end{thm}
\end{framed}
\subsection{Integral Calculus}
A very useful quantity for integration is
\begin{framed}
	\begin{thm}[Infintesimal length]
	\begin{align*}
		d\vb{l}&=dx\ \hat{e_x}+dy\ \hat{e_y}+dz\ \hat{e_z}\\
			   &=dr\ \hat{e_r}+r\ d\theta\ \hat{e_\theta}+r\sin\theta\ d\phi\ \hat{e_\phi}\\
			   &=ds\ \hat{e_s}+s\ d\phi\ \hat{e_\phi}+dz\ \hat{e_z}
	\end{align*}
\end{thm}
\end{framed}
Now, we may define some of the most important vector integrals in physics.
\begin{framed}
\begin{defn}[Line integral]
	\[\int_C \vb{A}\cdot d\vb{l}\]
\end{defn}

\begin{defn}[Surface integral]
	\[\iint_S \vb{A}\cdot d\pmb{\sigma}\]
	The contour enclosing a surface $S$ is represented by $\partial S$.
\end{defn}

\begin{defn}[Volume integral]
	\[\iiint_V \vb{A}\ d\tau\]
	The surface enclosing a volume $V$ is represented by $\partial V$.
\end{defn}
\end{framed}

Some important theorems that will help simplify integrals are
\begin{framed}
	\begin{thm}[Conservation of gradient]
		\[\int_C(\grad f)\cdot d\vb{l}=f(\vb{b})-f(\vb{a})\]
		where $\vb{a}, \vb{b}$ are the endpoints of $C$(which is directed from $\vb{a}$ to $\vb{b}$).
	\end{thm}
	\begin{thm}[Gauss]
		\[\varoiint_{\partial V} \vb{A}\cdot d\pmb{\sigma}=\iiint_V \grad\cdot \vb{A}\ d\tau\]
	\end{thm}

	\begin{thm}[Stokes]
		\[\oint_{\partial S} \vb{A}\cdot d\vb{l}=\iint_S (\grad\times\vb{A})\cdot d\pmb{\sigma}\]
	\end{thm}
	\hfill\\
	Note that $C,S,V$ need to be ``sufficiently nice" for these to be valid, which is often the case in physics.
\end{framed}

\end{document}
