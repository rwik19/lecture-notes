\documentclass[10pt, a4paper]{extarticle}
\usepackage{physics}
\usepackage{esint}
\usepackage{mathtools}
\usepackage{hyperref}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage[margin=0.75in]{geometry}
\usepackage{anyfontsize}
\usepackage{amsthm}
\usepackage{framed}


\theoremstyle{definition}
\newtheorem{thm}{Theorem}
\newtheorem{lem}{Lemma}[thm]
\newtheorem{cor}{Corollary}[thm]
\newtheorem{defn}{Definition}
\newtheorem{eg}{Example}
\newtheorem{ex}{Exercise}
\newtheorem*{note*}{Note}

\begin{document}
\begin{center}
	\fontsize{25}{60}\selectfont Mathematical Methods in Physics I \\
	\large Based on lectures by Dr. Ritam Mallick\\
	Notes taken by Rwik Dutta
\end{center}
\hrule
\begin{center}
	These notes are not endorsed by the lecturers, and I have modified them (often
	significantly) after lectures. They are nowhere near accurate representations of what
	was actually lectured, and in particular, all errors are almost surely mine.\footnote[1]{This is how Dexter Chua describes his lecture notes from Cambridge. I could not have described mine in any better way.}
\end{center}
\tableofcontents

\newpage

\section{Vector Analysis}
Let $\{\vu{e_i}\}$ be an orthonormal basis, i.e., $\vu{e_i}\cdot\vu{e_j}=\delta_{ij}$(where $\delta_{ij}$ represents the Kroneker delta function), of our vector space. For any vector $\vb{A}$ we have
\[\vb{A}=\sum_{i}A_i\vu{e_i}\]
where $A_i$ belong to the scalar field over which the vector space is defined, like $\mathbb{R}$ or $\mathbb{C}$.
\subsection{Products}
\begin{framed}
	\begin{defn}[Vector Product]
		We define a vector product on our basis set
		\[\vu{e_i}\times\vu{e_j}=\sum_k \epsilon_{ijk}\ \vu{e_k}\]
		The R.H.S. is a vector itself, hence, the name. Using this and the fact that vector product is distributive over addition we arrive at
		\[\vb{C}=\vb{A}\times\vb{B}=\sum_i \vu{e_i}\sum_{jk}\epsilon_{ijk}A_jB_k\]
		where \[C_i=\sum_{jk}\epsilon_{ijk}A_jB_k\]
	\end{defn}
\end{framed}
\hfill\\
Using this we can find
\begin{framed}
	\begin{thm}[Scalar triple product]
		\[\vb{A}\cdot(\vb{B}\times\vb{C})=\sum_{ijk}\epsilon_{ijk}A_iB_jC_k\]
		This is also represented as $[\vb{ABC}]$.
	\end{thm}
\end{framed}
\hfill\\
We can also calculate
\begin{framed}
	\begin{thm}[Vector triple product]
		\begin{align*}
			\vb{A}\times(\vb{B}\times\vb{C}) & =\sum_i \vu{e_i}\sum_{jk}\epsilon_{ijk}A_j\sum_{pq}\epsilon_{kpq}B_pC_q \\
			                                 & =\vb{B}(\vb{A}\cdot\vb{C})-\vb{C}(\vb{A}\cdot\vb{B})
		\end{align*}
		The vector product is not associative, hence the position of the parenthesis is important in the triple product.
	\end{thm}
\end{framed}

\begin{ex}
	Show that
	\[(\vb{A}\times\vb{B})\times(\vb{C}\times\vb{D})=[\vb{ABD}]\vb{C}-[\vb{ABC}]\vb{D}\]
\end{ex}

\subsection{Coordinate Transformation}
The rotation of the 2D coordinate axes by an angle $\phi$, keeping the origin fixed, leads to the
\begin{framed}
	\begin{defn}[Rotation transformation]
		\[\vb{A'}=S\vb{A}\]
		where $S$ is the rotation transformation represented by the matrix
		\[S=\left(\begin{matrix}
					\cos\phi  & \sin\phi \\
					-\sin\phi & \cos\phi
				\end{matrix}\right)\] in our orthonormal basis.
		It is clear that $SS^T=I$, i.e., the rotation transformation is orthogonal. It takes the same form in higher dimensions, i.e., rotation of vectors is an orthogonal transformation.
	\end{defn}
\end{framed}
This is a special property of vectors in physics. There is another kind of quantity called
\begin{framed}
	\begin{defn}[Pseudovectors]
		\[\vb{A'}=|S|S\vb{A}\]
		This is how these quantities transform under rotation, where, $S$ is again a orthogonal transformation and $|S|$ represents the determinant of $S$.
	\end{defn}
\end{framed}

\subsection{Differential Calculus}
We require the del operator
\[\grad\equiv \sum_i\vu{e_i}\pdv{}{i}\] in Cartesian coordinates. Using this we can define quantities like
\begin{framed}
	\begin{defn}[Gradient]
		\[\text{Grad }f=\grad f\]
		A small change in a scalar field along $\vb{r}$ is given by
		\[df=\vb{r}\cdot\grad f\]
		Say, the direction of $\grad f$ is given by some $\vu{r}$. We have the most rapid increase in $f$ along $\vu{r}$ and $|\grad f|=\frac{Df}{D\vu{r}}$ is the directional derivative of $f$ along $\vu{r}$.
	\end{defn}

	\begin{defn}[Divergence]
		\[\text{Div }\vb{A}=\div\vb{A}\]
		This gives a measure of the accumulation or depletion of $\vb{A}$ at a point. In other words, it finds how strongly a point acts as a source or sink. It is also known as the \emph{source density} of the vector field.
	\end{defn}

	\begin{defn}[Curl]
		\[\text{Curl }\vb{A}=\curl\vb{A}\]
		This gives a measure of the circulation of $\vb{A}$ at a point. It is also known as the \emph{circulation density} of the vector field.
	\end{defn}

	\begin{defn}[Laplacian]
		\[\laplacian f=\div(\grad f)\]
		The Laplacian is also defined for a vector field as
		\[\laplacian\vb{A}=\sum_i \vu{e_i}\laplacian A_i\]
	\end{defn}
\end{framed}
These can also be calculated in curvilinear coordinate systems as given in \href{https://en.wikipedia.org/wiki/Del_in_cylindrical_and_spherical_coordinates}{this Wikipedia article}. 

Some useful properties of vector derivatives are
\begin{framed}
	\begin{thm}
		\begin{align*}
			\curl(\grad f)&=0\\
			\div(\curl\vb{A})&=0\\
		\curl(\curl\vb{A})&=\grad(\div\vb{A})-\laplacian\vb{A}
		\end{align*}
		The last one is only valid in Cartesian coordinates.
	\end{thm}
\end{framed}
\begin{framed}
	\begin{thm}[Exact differential]
		$\sum_i A_i\ di$ is an exact differential iff $\curl \vb{A}=0$.
	\end{thm}
\end{framed}
Two special kinds of vector fields that often appear in physics are
\begin{framed}
	\begin{defn}[Solenoidal]
		\[\div\vb{A}=0\]
	\end{defn}
	\begin{defn}[Irrotational]
		\[\curl\vb{A}=0\]
	\end{defn}
\end{framed}
Vector fields can be decomposed into solenoidal and irrotational components using
\begin{framed}
	\begin{thm}[Helmholtz]
		Suppose, $\div \vb{F}$ and $\curl\vb{F}$ vanish at infinity and $\vb{F}$ is smooth. $\exists f,\vb{A}$ such that
		\[\vb{F}=\underbrace{-\grad f}_{\text{irrotational}}+\underbrace{\curl\vb{A}}_{\text{solenoidal}}\]
	\end{thm}
\end{framed}
\subsection{Integral Calculus}
A very useful quantity for integration is
\begin{framed}
	\begin{thm}[Infintesimal length]
	\begin{align*}
		d\vb{l}&=dx\ \vu{e_x}+dy\ \vu{e_y}+dz\ \vu{e_z}\\
			   &=dr\ \vu{e_r}+r\ d\theta\ \vu{e_\theta}+r\sin\theta\ d\phi\ \vu{e_\phi}\\
			   &=ds\ \vu{e_s}+s\ d\phi\ \vu{e_\phi}+dz\ \vu{e_z}
	\end{align*}
\end{thm}
\end{framed}
Now, we may define some of the most important vector integrals in physics.
\begin{framed}
\begin{defn}[Line integral]
	\[\int_C \vb{A}\cdot d\vb{l}\]
\end{defn}

\begin{defn}[Surface integral]
	\[\iint_S \vb{A}\cdot d\pmb{\sigma}\]
	The contour enclosing a surface $S$ is represented by $\partial S$.
\end{defn}

\begin{defn}[Volume integral]
	\[\iiint_V \vb{A}\ d\tau\]
	The surface enclosing a volume $V$ is represented by $\partial V$.
\end{defn}
\end{framed}

Some important theorems that will help simplify integrals are
\begin{framed}
	\begin{thm}[Conservation of gradient]
		\[\int_C(\grad f)\cdot d\vb{l}=f(\vb{b})-f(\vb{a})\]
		where $\vb{a}, \vb{b}$ are the endpoints of $C$(which is directed from $\vb{a}$ to $\vb{b}$).
	\end{thm}
	\begin{thm}[Green]
		\[\oint_{\partial S}P(x,y)\ dx+Q(x,y)\ dy=\iint_S\left(\pdv{Q}{x}-\pdv{P}{y}\right)\ dA\]
	\end{thm}
	\begin{thm}[Gauss]
		\[\varoiint_{\partial V} \vb{A}\cdot d\pmb{\sigma}=\iiint_V \div \vb{A}\ d\tau\]
	\end{thm}

	\begin{thm}[Stokes]
		\[\oint_{\partial S} \vb{A}\cdot d\vb{l}=\iint_S (\curl\vb{A})\cdot d\pmb{\sigma}\]
	\end{thm}
	\hfill\\
	Note that $C,S,V$ need to be ``sufficiently nice" for these to be valid, which is often the case in physics.
\end{framed}

\subsection{Orthogonal Curvilinear Coordinate Systems}
Let $\vu{q_i}$ be the unit vectors of our generalized system. We would like to transform among coordinate systems.
\begin{note*}
	A vector $\vb{A}$ can be written as $\sum_i A_i\vu{q_i}$ in the generalized coordinate system. However, the position $\vb{r}\neq \sum_i q_i\vu{q_i}$, in general though the equality holds in Cartesian system.
\end{note*}
The square of the infinitesimal arc length is given by $d\vb{r}\cdot d\vb{r}=ds^2=dx^2+dy^2+dz^2$ in Cartesian coordinates. This arc length is invariant of our coordinate system.
\[ds^2=\sum_{ij}g_{ij}\ dq_i\ dq_j\]
		The $g_{ij}$ depend on the geometry of the coordinate system and are given by
		\[g_{ij}=\pdv{\vb{r}}{q_i}\cdot\pdv{\vb{r}}{q_j}\]
		For orthogonality,
		\[g_{ij}=0,\ i\neq j\]\[\vu{q_i}\cdot\vu{q_j}=\delta_{ij}\]
		We can take $g_{ii}=h_i^2>0$. Now, to represent $d\vb{r}$ in our generalized orthogonal coordinate system, we use
\begin{framed}
	\begin{thm}[Scale factors]
		\[ds^2=\sum_i(h_i\ dq_i)^2\]
		\[d\vb{r}=\sum_i h_i\ dq_i\vu{q_i}\]
		\[\pdv{\vb{r}}{q_i}=h_i\vu{q_i}\]
	\end{thm}
\end{framed}
Thus, we can define our differential operators as
\begin{framed}
	\begin{defn}[Gradient]
		\[\grad{\phi}=\frac{1}{h_1}\pdv{\phi}{q_i}\vu{q_i}\]
	\end{defn}
	\begin{defn}[Divergence]
		\[\div{\vb{A}}=\frac{1}{h_1h_2h_3}\sum_{ijk}\epsilon_{ijk}\pdv{A_i}{q_i}h_jh_j\]
	\end{defn}
	\begin{defn}[Curl]
		\[\curl{\vb{A}}=\frac{1}{h_1h_2h_3}\left|
			\begin{matrix}
				h_1\vu{q_1}&h_2\vu{q_2}&h_3\vu{q_3}\\
				\pdv{}{q_1}&\pdv{}{q_2}&\pdv{}{q_3}\\
				h_1A_1&h_2A_2&h_3A_3
			\end{matrix}
		\right|\]
	\end{defn}
\end{framed}

\end{document}
