\documentclass[10pt, a4paper]{extarticle}
\usepackage{physics}
\usepackage{mathtools}
\usepackage{hyperref}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage[margin=0.75in]{geometry}
\usepackage{anyfontsize}
\usepackage{amsthm}
\usepackage{framed}

\theoremstyle{definition}
\newtheorem{thm}{Theorem}
\newtheorem{lem}{Lemma}[thm]
\newtheorem{cor}{Corollary}[thm]
\newtheorem{defn}{Definition}
\newtheorem{eg}{Example}
\newtheorem*{note*}{Note}
\newtheorem*{hyp*}{Hypothesis}

\begin{document}
\begin{center}
	\fontsize{25}{60}\selectfont Statistical Mechanics \\
	\large Based on lectures by Dr. Suvankar Dutta\\
	Notes taken by Rwik Dutta
\end{center}
\hrule
\begin{center}
	These notes are not endorsed by the lecturers, and I have modified them (often
	significantly) after lectures. They are nowhere near accurate representations of what
	was actually lectured, and in particular, all errors are almost surely mine.\footnote[1]{This is how Dexter Chua describes his lecture notes from Cambridge. I could not have described mine in any better way.}
\end{center}
\tableofcontents

\newpage

\section{Ensemble}
\begin{defn}[Macroscopic variables]
	The variables of a system that can be controlled externally or determined experimentally. They are also called thermodynamic variables.

	For e.g., volume, pressure, temperature, etc.
\end{defn}
\begin{defn}[Microscopic variables]
	These parameters are not under any control.

	For e.g., the coordinates of a molecule of a gaseuos system.
\end{defn}
\begin{defn}[Ensemble]
	Set of identical copies of the same system which are same at the macroscopic level but different at the microscopic level.
\end{defn}
\subsection{Phase Space}
In the case of 1D motion of a single particle, the phase space is represented by the $p,q$--plane, where $p,q$ represent the momentum and position of the paticle, respectively. The collection of points $(q,p)$ that are possible classical states of the particle is called the phase space trajectory(or surface) of the particle. This trajectory can be found by
\[E=\mathcal{H}(q,p)=\frac{p^2}{2m}+V(q)\]
where $E$ represents the classically allowed energy states of the system.
\begin{eg}[Classical Harmonic Oscillator]
	In this case $E$ is a constant of motion and $V(q)=-\frac{1}{2}m\omega^2q^2$. So we have
	\[\frac{p^2}{2m}-\frac{1}{2}m\omega^2q^2=E\]
	This is an ellipse in the $p,q$--plane. The direction of the trajectory depends on the boundary conditions.
\end{eg}
\begin{framed}
	Thus, the phase space trajectory tells us about the possible states of the particle(or, system) and how one state evolves into another.
\end{framed}
\hfill\\
Now, we extend this idea to $N$ particles in 3 dimensions. This time instead of just two quantities $p,q$, we require the 3 position and 3 momentum coordinates of each of the $N$ particles. Provided there are no additional constrains, in general, we require a $6N$ dimensional phase space to describe the states of this system. Thus, $E=\mathcal{H}$ represents a $6N-1$ dimensional hypersurface in this phase space.
\begin{note*}
	$\mathcal{H}$ is a function of all the $6N$ positions and momenta.
\end{note*}
\begin{note*}
	If $E$ is continuous, say we have energy between $E$ and $E+\Delta E$, we get a $6N$ dimensional region in the phase space.
\end{note*}

\subsection{Ensemble of a classical gas}
We need to understand the ensemble for a gas of $N$ particles in volume $V$ and energy between $E$ and $E+\Delta E$.

All the states of this system can be represented as a $6N$ dimensional region $\Gamma$ in the $6N$ dimensional phase space.

Say, we have an initial state $(q,p)$ of our system. Here, $(q,p)$ is a shorthand notation for $(q_1,\cdots,q_{3N},p_1,\cdots,p_{3N})$. $(q,p)$ represents some point in $\Gamma$. As time passes, the point `swims' in $\Gamma$. 

From here onwards, when we say `phase space' we will be talking about $\Gamma$, i.e., the region of allowed states.

Now, our system can be in any point(state) in $\Gamma$ but its macroscopic properties would not change, i.e. energy would still lie between $E$ and $E+\Delta E$ and its volume would still be $V$.

Hence, the region $\Gamma$ forms an ensemble. Every point in $\Gamma$ is an ensemble member called a \emph{microstate}. Each microstate represents the system at some point in time.

\begin{defn}[Unit cell in phase space]
	We assume that there exists some small hypercube in the phase space inside which all points represent the same state. Its volume is given by $h_0^{3N}$.

	Ideally, this hypercube should be infinesimally small as every point represents a different state. Hence, we will later take the limit as $h_0\to 0$.

	Also, the physics of our system(measurable quantities) should not depend on $h_0$.
\end{defn}
\begin{note*}
	A unit cell represents a single microstate of the system as all points in it are equivalent.
\end{note*}
\begin{note*}
	$h_0$ has the dimension of angular momentum.
\end{note*}

A differential volume in the phase space is given by
\[dq_1\cdots dq_{3N}dp_1\cdots dp_{3N}\equiv d^{3N}q\ d^{3N}p\]
The total number of microstates(unit cells) in this differential volume is then
\[\frac{d^{3N}q\ d^{3N}p}{h_0^{3N}}\]
\begin{framed}
Suppose, the probability of finding the system in a microstate $(q,p)$ at time $t$ is $\rho(q,p,t)$.\\
All points within a differential volume element containing $(q,p)$ effectively represent the same microstate. Hence, the `probability' of finding the system in the volume $d^{3N}q\ d^{3N}p$ is given by \[\rho(q,p,t)\frac{d^{3N}q\ d^{3N}p}{h_0^{3N}}\]
\begin{note*}
	This probability is not normalized. To normalize this
	\begin{align*}
		\mathcal{N}\int_{\Gamma}\rho(q,p,t)\frac{d^{3N}q\ d^{3N}p}{h_0^{3N}}=1\\
		\implies \mathcal{N}=\frac{1}{\int_{\Gamma}\rho(q,p,t)\frac{d^{3N}q\ d^{3N}p}{h_0^{3N}}}
	\end{align*}
\end{note*}
\end{framed}
We want to calculate the average(over all the possible microstates) of any macroscopic property $F(q,p,t)$ of the system. This average is called the
\begin{framed}
	\begin{defn}[Ensemble average]
		\begin{align*}
			\langle F\rangle_E&=\frac{\int_{\Gamma}F\ \rho(q,p,t)\frac{d^{3N}q\ d^{3N}p}{h_0^{3N}}}{\int_{\Gamma}\rho(q,p,t)\frac{d^{3N}q\ d^{3N}p}{h_0^{3N}}}\\
							  &=\frac{\int_{\Gamma}F\rho(q,p,t)d^{3N}q\ d^{3N}p}{\int_{\Gamma}\rho(q,p,t)d^{3N}q\ d^{3N}p}\\
							  &=\int_{\Gamma}d^{3N}qd^{3N}p\ F\ P(q,p,t)
		\end{align*}
		$P$ is just the normalized version of $\rho$.
	\end{defn}
	\begin{note*}
		The ensemble average of a macroscopic parameter does not depend on $h_0$ which makes sense.
	\end{note*}
\end{framed}

In actual experiments, we measure the
\begin{framed}
	\begin{defn}[Time average]
		\[\langle F\rangle_T=\lim_{T\to +\infty}\frac{1}{T}\int_0^T F(t)\ dt\]
	\end{defn}
\end{framed}
\begin{note*}
	For the formulation of statistical mechanics to be valid, we must have $\langle F\rangle_E=\langle F\rangle_T$.
\end{note*}

\subsection{Ergodic Hypothesis}
Let us look into the time average in detail. We assume that our observable $F$ does not explicitly depend on time, i.e., a change in $F$ is only caused by a change in the microstate and not by when we measure the same microstate.
\[\therefore \langle F\rangle_T=\lim_{T\to\infty}\frac{1}{T}\int_{0}^T F(q(t),p(t))\ dt\]
Let us now divide the phase space into $M$ volume elements. Let the total time spent by the system in the $i$\textsuperscript{th} volume element, be $T_i$. Note that the system may visit the the $i$\textsuperscript{th} volume element several times but we are only concerned with the total time it spends there. Clearly,
\[\sum_{i=1}^{M}T_i=T\]
Also, if we take these volume elements to be infintesimally small, $(q,p)$ does not change much inside each volume element. Let $(q_i,p_i)$ be the state of the system in the $i$\textsuperscript{th} volume element.
\[\therefore \langle F\rangle_T=\lim_{T\to\infty}\frac{1}{T}\sum_{i=1}^M F(q_i,p_i)T_i\]
Now, $\tilde{P}(i)=\frac{T_i}{T}$ is simply the probability of finding the system in the $i$\textsuperscript{th} volume element.

\[\therefore\langle F\rangle_T=\lim_{T\to\infty}\sum_{i=1}^M F(q_i,p_i)\tilde{P}(i)\]
In the continuous limit, instead of summing over $M$ discrete volume elements we can take an integral over the phase space.
\[\therefore \langle F\rangle_T =\int_{\Gamma}d^{3N}q\ d^{3N}p\ F(q,p)\tilde{P}(q,p)\]
\begin{framed}
\begin{hyp*}[Ergodic hypothesis]
	If one waits for a sufficient amount of time, the system visits all its possible microstates.

	This means that in the limit $T\to\infty$, the system visits all the volume elements several times. Hence,
	\[P(q,p)=\tilde{P}(q,p)\]\[\therefore \langle F\rangle_E=\langle F\rangle_T\]
\end{hyp*}
\end{framed}
\begin{note*}
	There is no reason to assume that $P(q,p)=\tilde{P}(q,p)$ a priori. While $P$ is the probability that tells us how many microstates there is in some volume element, $\tilde{P}$ tells us how much time the system spends in that volume element.

	From the Ergodic hypothesis, it is clear that the time the system spends in a volume element of the phase space is propotional to the number of microstates in that volume element, provided we observe the system for a sufficiently long(ideally, infinite) amount of time. As a result the ensemble average(calculated in statistical mechanics) of an observable is equal to its time average(measured in experiment).

	Thus, the Ergodic hypothesis forms the backbone of statistical mechanics.
\end{note*}
\end{document}
